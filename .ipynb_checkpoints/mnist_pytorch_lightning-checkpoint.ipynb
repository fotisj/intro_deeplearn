{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cacaa1d7",
   "metadata": {},
   "source": [
    "# Introduction into deep learning with pytorch and pytorch-lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99bdfd2",
   "metadata": {},
   "source": [
    "Example code for a simple multilayered perceptron. Main function to make acquainted with a specific structure: \n",
    "\n",
    "* data preparation\n",
    "* model definition\n",
    "* initialize model and trainer\n",
    "* set up progress/performance logging (optional)\n",
    "* training\n",
    "* model evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "520d7b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import MNIST\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, seed_everything\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d789a200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preparation\n",
    "\n",
    "#defines a sequence of transformation for the images\n",
    "transform = transforms.Compose([transforms.ToTensor(),                     # ToTensor(): Convert a PIL Image or numpy.ndarray to tensor\n",
    "                                transforms.Normalize(mean=0.5, std=0.5)])  #Normalize a tensor image with mean and standard deviation\n",
    "\n",
    "#prepares the data, downloads if necessary and applies transformations defined above\n",
    "training_data = MNIST(root=\"data\",     \n",
    "                      train=True,\n",
    "                      download=True,\n",
    "                      transform=transform)\n",
    "#same for the test data\n",
    "test_data = MNIST(root=\"data\",\n",
    "                  train=False,\n",
    "                  download=True,\n",
    "                  transform=transform)\n",
    "\n",
    "#splits the training data into training and validation data\n",
    "training_data, validation_data = random_split(training_data, [55_000, 5_000])\n",
    "\n",
    "#feeds our data into dataloaders which handle shuffling, creating batches, distribution over cores etc.\n",
    "training_data = DataLoader(training_data, batch_size=64, shuffle=True, num_workers=4)\n",
    "validation_data = DataLoader(validation_data, batch_size=64, shuffle=False, num_workers=4)\n",
    "test_data = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c99ab086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model definition\n",
    "class MNISTModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #defining the layers\n",
    "        self.layer_1 = nn.Linear(1 * 28 * 28, 512)   #1*28*28: channel * height * width; 256 is the output of this layer\n",
    "        self.layer_2 = nn.Linear(512, 10)            #input 256 and output: 10\n",
    "        self.dropout = nn.Dropout(0.15)              #defines a dropout layer \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        #defining metric logger\n",
    "        self.train_acc = Accuracy()\n",
    "        self.val_acc = Accuracy()\n",
    "        self.test_acc = Accuracy()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        #here we define the complete model\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.layer_1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_2(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        #applying the model and computing the loss and some reporting/logging\n",
    "        x, y = batch\n",
    "        y_pred = self(x)   #this is the forward step: compute the prediction\n",
    "        loss = F.cross_entropy(y_pred, y)  #compute the loss\n",
    "        \n",
    "        #the rest is reporting: size of loss and accuracy\n",
    "        accuracy = self.train_acc(y_pred, y) #\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', accuracy)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        #same as training, but without backpropagation, and using our validation data\n",
    "        #if used, usually done during the training\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        self.val_acc.update(y_pred, y)        \n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", self.val_acc, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_nb):\n",
    "        #as validation but only done once after the model is trained \n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        accuracy = self.test_acc(y_pred, y)\n",
    "        self.log('test_loss', loss)            \n",
    "        self.log(\"test_acc\", accuracy)        \n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        #here we define our optimizer which is used for the backpropagation\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.0005)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bb5430",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize model and trainer\n",
    "\n",
    "# Initialize the model\n",
    "mnist_model = MNISTModel()\n",
    "\n",
    "# Initialize a trainer\n",
    "trainer = Trainer(max_epochs=10,     #number of epochs: in one epoch all training data is processed once.\n",
    "                  accelerator='gpu') #if your computer has a NVIDIA gpu, you can accelerate the training, otherwise: 'None'\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fa43615",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4d17c2a11a0b485d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4d17c2a11a0b485d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#reporting / logging\n",
    "\n",
    "#to log our training results we use tensorboard, we load it here and \n",
    "#then use the refresh button during training to see the current run\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "127d2fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type     | Params\n",
      "---------------------------------------\n",
      "0 | layer_1   | Linear   | 401 K \n",
      "1 | layer_2   | Linear   | 5.1 K \n",
      "2 | dropout   | Dropout  | 0     \n",
      "3 | flatten   | Flatten  | 0     \n",
      "4 | train_acc | Accuracy | 0     \n",
      "5 | val_acc   | Accuracy | 0     \n",
      "6 | test_acc  | Accuracy | 0     \n",
      "---------------------------------------\n",
      "407 K     Trainable params\n",
      "0         Non-trainable params\n",
      "407 K     Total params\n",
      "1.628     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f8fab802dbf4d21b6a64602fe16b334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#training\n",
    "\n",
    "# Train the model: links the trainer to the model, using our training and validation data\n",
    "#you can watch the progress, by going back to the tensorboard\n",
    "trainer.fit(model = mnist_model, \n",
    "            train_dataloaders=training_data,\n",
    "            val_dataloaders=validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3708515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at D:\\mydata\\Dropbox\\uni\\Würzburg\\lehre\\seminare\\einführung in deep learning\\notebooks\\lightning_logs\\version_4\\checkpoints\\epoch=9-step=8600.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at D:\\mydata\\Dropbox\\uni\\Würzburg\\lehre\\seminare\\einführung in deep learning\\notebooks\\lightning_logs\\version_4\\checkpoints\\epoch=9-step=8600.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80222208b3b64b9b9bd1116b24f98dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.9785000085830688\r\n",
      "        test_loss           0.06816816329956055\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.06816816329956055, 'test_acc': 0.9785000085830688}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#post training: evaluate the  model on test data\n",
    "# we use the best model to test on unseen data. This is the real test for the performance of a model \n",
    "# and the numbers researcher report in papers.\n",
    "trainer.test(ckpt_path='best', dataloaders=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c6fe82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
